{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8841cd36-01b0-4cd0-9675-4942b48777f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict\n",
    "from swarmauri.standard.models.concrete.OpenAIModel import OpenAIModel\n",
    "from swarmauri.standard.vector_stores.concrete.TFIDFVectorStore import TFIDFVectorStore\n",
    "from swarmauri.standard.vector_stores.concrete.Doc2VecVectorStore import Doc2VecVectorStore\n",
    "from swarmauri.standard.vector_stores.concrete.MLMVectorStore import MLMVectorStore\n",
    "from swarmauri.standard.conversations.concrete.LimitedSystemContextConversation import LimitedSystemContextConversation\n",
    "#from swarmauri.standard.agents.concrete.RagAgent import RagAgent\n",
    "from typing import Any, Optional, Union, Dict\n",
    "from swarmauri.core.messages import IMessage\n",
    "from swarmauri.core.models.IModel import IModel\n",
    "from swarmauri.standard.conversations.base.SystemContextBase import SystemContextBase\n",
    "from swarmauri.standard.agents.base.VectorStoreAgentBase import VectorStoreAgentBase\n",
    "from swarmauri.standard.vector_stores.base.VectorDocumentStoreRetrieveBase import VectorDocumentStoreRetrieveBase\n",
    "from swarmauri.standard.documents.concrete.Document import Document\n",
    "from swarmauri.standard.documents.concrete.EmbeddedDocument import EmbeddedDocument\n",
    "from swarmauri.standard.messages.concrete import (HumanMessage, \n",
    "                                                  SystemMessage,\n",
    "                                                  AgentMessage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca14f6c3-9084-4b83-a44e-7d15fd9ff769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_from_json_file(json_file_path):\n",
    "    documents = []\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    documents = [EmbeddedDocument(id=str(_), content=doc['content'], metadata={\"document_name\": doc['document_name']}) for _, doc in enumerate(data) if doc['content']]\n",
    "    return documents\n",
    "    \n",
    "class RagAgent(VectorStoreAgentBase):\n",
    "    \"\"\"\n",
    "    RagAgent (Retriever-And-Generator Agent) extends DocumentAgentBase,\n",
    "    specialized in retrieving documents based on input queries and generating responses.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, model: IModel, conversation: SystemContextBase, vector_store: VectorDocumentStoreRetrieveBase):\n",
    "        super().__init__(name=name, model=model, conversation=conversation, vector_store=vector_store)\n",
    "\n",
    "    def exec(self, \n",
    "             input_data: Union[str, IMessage], \n",
    "             top_k: int = 5, \n",
    "             model_kwargs: Optional[Dict] = {}\n",
    "             ) -> Any:\n",
    "        conversation = self.conversation\n",
    "        model = self.model\n",
    "\n",
    "        # Check if the input is a string, then wrap it in a HumanMessage\n",
    "        if isinstance(input_data, str):\n",
    "            human_message = HumanMessage(input_data)\n",
    "        elif isinstance(input_data, IMessage):\n",
    "            human_message = input_data\n",
    "        else:\n",
    "            raise TypeError(\"Input data must be a string or an instance of Message.\")\n",
    "        \n",
    "        # Add the human message to the conversation\n",
    "        conversation.add_message(human_message)\n",
    "        \n",
    "        \n",
    "        if top_k > 0:\n",
    "            similar_documents = self.vector_store.retrieve(query=input_data, top_k=top_k)\n",
    "            substr = '\\n'.join([doc.content for doc in similar_documents])\n",
    "            self.last_similar_documents = similar_documents\n",
    "        else:\n",
    "            substr = \"\"\n",
    "            self.last_similar_documents = []\n",
    "\n",
    "        \n",
    "        # Use substr to set system context\n",
    "        system_context = SystemMessage(substr)\n",
    "        conversation.system_context = system_context\n",
    "        \n",
    "\n",
    "        # Retrieve the conversation history and predict a response\n",
    "        messages = conversation.as_dict()\n",
    "        if model_kwargs:\n",
    "            prediction = model.predict(messages=messages, **model_kwargs)\n",
    "        else:\n",
    "            prediction = model.predict(messages=messages)\n",
    "            \n",
    "        # Create an AgentMessage instance with the model's response and update the conversation\n",
    "        agent_message = AgentMessage(prediction)\n",
    "        conversation.add_message(agent_message)\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "306fc1bf-a03c-473d-8d1a-2ff839752656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing... this will take a moment.\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RagAssistant:\n",
    "    def __init__(self, api_key: str = \"\", db_path='prompt_responses.db', vector_store_path=None):\n",
    "        print('Initializing... this will take a moment.')\n",
    "        self.api_key = api_key\n",
    "        self.db_path = db_path\n",
    "        self.conversation = LimitedSystemContextConversation(max_size=36, system_message_content=\"\")\n",
    "        self.model = OpenAIModel(api_key=self.api_key, model_name=\"gpt-4-0125-preview\")\n",
    "        self.retrieval_table = []\n",
    "        self.document_table = []\n",
    "        self.agent = self.initialize_agent()\n",
    "        self.css = \"\"\"\n",
    "#chat-dialogue-container {\n",
    "    min-height: 54vh !important;\n",
    "}\n",
    "\n",
    "#document-table-container {\n",
    "    min-height: 80vh !important;\n",
    "}\n",
    "\n",
    "footer {\n",
    "    display: none !important;\n",
    "}\n",
    "\"\"\"\n",
    "        self.setup_gradio_interface()\n",
    "        \n",
    "    def initialize_agent(self):\n",
    "        VS = Doc2VecVectorStore()\n",
    "        agent = RagAgent(name=\"Rag\", model=self.model, conversation=self.conversation, vector_store=VS)\n",
    "        return agent\n",
    "\n",
    "    def change_vectorizer(self, vectorizer: str):\n",
    "        if vectorizer == 'Doc2Vec':\n",
    "            self.agent.vector_store = Doc2VecVectorStore()\n",
    "        if vectorizer == 'MLM':\n",
    "            self.agent.vector_store = MLMVectorStore()\n",
    "        else:\n",
    "            self.agent.vector_store = TFIDFVectorStore()\n",
    "            \n",
    "    \n",
    "    def load_and_filter_json(self, file_info):\n",
    "        # Load JSON file using json library\n",
    "        try:\n",
    "            documents = load_documents_from_json_file(file_info.name)\n",
    "            self.agent.vector_store.documents = []\n",
    "            self.agent.vector_store.add_documents(documents)\n",
    "            return self.preprocess_documents(documents)\n",
    "        except json.JSONDecodeError:\n",
    "            return \"Invalid JSON file. Please check the file and try again.\"\n",
    "\n",
    "    def preprocess_documents(self, documents):\n",
    "        try:\n",
    "            docs = [d.to_dict() for d in documents]\n",
    "            for d in docs:\n",
    "                metadata = d['metadata']\n",
    "                for each in metadata:\n",
    "                    d[each] = metadata[each]\n",
    "                del d['metadata']\n",
    "                del d['type']\n",
    "                del d['embedding']\n",
    "            df = pd.DataFrame.from_dict(docs)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"postprocess_documents: {e}\")\n",
    "\n",
    "    \n",
    "    def sql_log(self, prompt, response):\n",
    "        try:\n",
    "            conn = sqlite3.connect(self.db_path)\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute('''CREATE TABLE IF NOT EXISTS prompts_responses\n",
    "                            (id INTEGER PRIMARY KEY AUTOINCREMENT, prompt TEXT, response TEXT)''')\n",
    "            cursor.execute('''INSERT INTO prompts_responses (prompt, response) VALUES (?, ?)''', (prompt, response))\n",
    "            conn.commit()\n",
    "            conn.close()\n",
    "        except:\n",
    "            raise\n",
    "    \n",
    "    def save_df(self, df):\n",
    "        ...\n",
    "\n",
    "    async def chatbot_function(self, \n",
    "                         message, \n",
    "                         history, \n",
    "                         api_key: str = None, \n",
    "                         model_name: str = None, \n",
    "                         top_k: int = 5, \n",
    "                         temperature: int = 1, \n",
    "                         max_tokens: int = 256):\n",
    "        try:\n",
    "            if self.agent.vector_store.document_count() == 0:\n",
    "                return \"\", [], [(message, \"⚠️ Add Documents First\")]\n",
    "            else:\n",
    "                # Set additional parameters\n",
    "                self.agent.model.model_name = model_name\n",
    "                self.agent.model.api_key = api_key\n",
    "                \n",
    "                # Predict\n",
    "                response = self.agent.exec(message, top_k=top_k, model_kwargs={'temperature': temperature, 'max_tokens': max_tokens})\n",
    "                \n",
    "                self.sql_log(message, response)\n",
    "    \n",
    "                # Update Retrieval Document Table\n",
    "                df = self.preprocess_documents(self.agent.last_similar_documents)\n",
    "                \n",
    "                # Get History\n",
    "                history = [each['content'] for each in self.agent.conversation.as_dict()][1:]\n",
    "                history = [(history[i], history[i+1]) for i in range(0, len(history), 2)]\n",
    "\n",
    "                return \"\", df, history\n",
    "        except Exception as e:\n",
    "            print(f\"chatbot_function error: {e}\")\n",
    "            return \"\", [], history\n",
    "    \n",
    "    def clear_chat(self):\n",
    "        self.agent.conversation.clear_history()\n",
    "        return \"\", [], []\n",
    "        \n",
    "    def setup_gradio_interface(self):\n",
    "\n",
    "        with gr.Blocks(css=self.css) as self.retrieval_table:\n",
    "            with gr.Row():\n",
    "                self.retrieval_table = gr.Dataframe(interactive=False, wrap=True, line_breaks=True, elem_id=\"document-table-container\")\n",
    "        \n",
    "        with gr.Blocks(css=self.css) as self.chat:\n",
    "            self.chat_history = gr.Chatbot(label=\"Chat History\", \n",
    "                                           layout=\"panel\", \n",
    "                                           elem_id=\"chat-dialogue-container\", \n",
    "                                           container=True, \n",
    "                                           show_copy_button=True,\n",
    "                                           height=\"70vh\")\n",
    "            with gr.Row():\n",
    "                self.input_box = gr.Textbox(label=\"Type here:\", scale=6)\n",
    "                self.send_button = gr.Button(\"Send\", scale=1)\n",
    "                self.clear_button = gr.Button(\"Clear\", scale=1)\n",
    "                \n",
    "            with gr.Accordion(\"See Details\", open=False):\n",
    "                self.additional_inputs = [\n",
    "                    gr.Textbox(label=\"Openai API Key\", value=self.api_key or \"Enter your Openai API Key\"),\n",
    "                    gr.Dropdown([\"gpt-3.5-turbo\", \"gpt-3.5-turbo-16k\", \"gpt-4-0125-preview\"], \n",
    "                                value=\"gpt-3.5-turbo\", \n",
    "                                label=\"Model\",\n",
    "                                info=\"Select openai model\"),\n",
    "                    gr.Slider(label=\"Top K\", value=10, minimum=0, maximum=100, step=5, interactive=True),\n",
    "                    gr.Slider(label=\"Temperature\", value=1, minimum=0.0, maximum=1.5, step=0.05, interactive=True),\n",
    "                    gr.Slider(label=\"Max new tokens\", value=256, minimum=256, maximum=4096, step=64, interactive=True)\n",
    "                ]\n",
    "    \n",
    "    \n",
    "            submit_inputs = [self.input_box, self.chat_history]\n",
    "            submit_inputs.extend(self.additional_inputs)\n",
    "            # Function to handle sending messages\n",
    "            self.send_button.click(\n",
    "                self.chatbot_function, \n",
    "                inputs=submit_inputs, \n",
    "                outputs=[self.input_box, self.retrieval_table, self.chat_history]\n",
    "            )\n",
    "        \n",
    "            # Function to handle clearing the chat\n",
    "            self.clear_button.click(\n",
    "                self.clear_chat, \n",
    "                inputs=[], \n",
    "                outputs=[self.input_box, self.retrieval_table, self.chat_history]\n",
    "            )\n",
    "\n",
    "        \n",
    "        with gr.Blocks(css=self.css) as self.document_table:\n",
    "            with gr.Row():\n",
    "                self.file = gr.File(label=\"Upload JSON File\")\n",
    "                self.vectorizer = gr.Dropdown(choices=[\"Doc2Vec\", \"TFIDF\", \"MLM\"], value=\"Doc2Vec\", label=\"Select vectorizer\")\n",
    "                self.load_button = gr.Button(\"load\")\n",
    "            with gr.Row():\n",
    "                self.data_frame = gr.Dataframe(interactive=True, wrap=True, line_breaks=True, elem_id=\"document-table-container\")\n",
    "            with gr.Row():\n",
    "                self.save_button = gr.Button(\"save\")\n",
    "                \n",
    "            self.vectorizer.change(self.change_vectorizer, inputs=[self.vectorizer], outputs=self.data_frame)\n",
    "            self.load_button.click(self.load_and_filter_json, inputs=[self.file], outputs=self.data_frame)\n",
    "            self.save_button.click(self.save_df, inputs=[self.data_frame])\n",
    "\n",
    "\n",
    "       \n",
    "        self.app = gr.TabbedInterface([self.chat, self.retrieval_table, self.document_table], [\"chat\", \"retrieval\", \"documents\"])\n",
    "\n",
    "    \n",
    "    def launch(self):\n",
    "        self.app.launch(share=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rag_assistant = RagAssistant(api_key=\"<your-openai-key>\")\n",
    "    rag_assistant.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarmauri",
   "language": "python",
   "name": "swarmauri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
